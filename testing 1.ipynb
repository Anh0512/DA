{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "# đọc dữ liệu\n",
    "df = pd.read_csv(\"FoodPrice_in_Turkey.csv\")\n",
    "# in ra kich thuoc du lieu\n",
    "df.shape\n",
    "\n",
    "\n",
    "#check giá trị khuyết thiếu\n",
    "check_GT= df.isna().values.any()\n",
    "\n",
    "#sns.boxplot(x=df['Price'])  # vẽ box plot cho dữ liệu ở cột Price\n",
    "\n",
    "\n",
    "#Xóa dữ liệu ngoại lai bằng IQR scoreIn [ ]:\n",
    "Q1 = df['Price'].quantile(0.25)\n",
    "Q3 = df['Price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# xác định phần tử không phải ngoại lai\n",
    "df2 = df\n",
    "df2['outlier'] = ~((df['Price'] < (Q1 - 1.5*IQR)) | (df['Price'] > (Q3 + 1.5*IQR)))\n",
    "\n",
    "# xóa phần tử ngoại lai\n",
    "df2 = df2[df2['outlier'] == True]\n",
    "\n",
    "\n",
    "#sns.boxplot(x=df2['Price'])  # vẽ box plot cho dữ liệu ở cột Price\n",
    "\n",
    "#=============CHUẨN HÓA DỮ LIỆU============\n",
    "\n",
    "# mô tả dữ liệu\n",
    "df2['Price'].describe()\n",
    "#biểu đồ phân bố dữ liệu\n",
    "#sns.kdeplot(data=df2['Price'])\n",
    "\n",
    "# chuẩn hóa dữ liệu với minmax scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Chuẩn hóa dữ liệu trong df với Min max scaling ở 2 cột Price\n",
    "df_s = scaler.fit_transform(df2[['Price']])\n",
    "#mô tả dữ liệu sau chuẩn hóa\n",
    "pd.DataFrame(df_s).describe()\n",
    "# vẽ lại biểu đồ hộp\n",
    "#sns.boxplot(x=df_s)\n",
    "# biểu đồ phân bố dữ liệu\n",
    "#sns.kdeplot(data=df_s)\n",
    "\n",
    "\n",
    "#=================MÃ HÓA DỮ LIỆT===============\n",
    "\n",
    "df2['ProductName'].unique()\n",
    "\n",
    "\n",
    "# mã hóa cột ProductName với One-hot encoder sử dụng scikit learn\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "encoded_data = encoder.fit_transform(np.asarray(df2['ProductName']).reshape(-1,1))\n",
    "encoded_data.todense()\n",
    "\n",
    "\n",
    "# mã hóa cột ProductName với One-hot encoder sử dụng pandas\n",
    "pd.get_dummies(df2['ProductName'])\n",
    "\n",
    "# mã hóa cột ProductName với Label encoder sử dụng scikit learn\n",
    "encoder = LabelEncoder()\n",
    "encoded_data = encoder.fit_transform(np.asarray(df2['ProductName']))\n",
    "\n",
    "#check\n",
    "pd.value_counts(encoded_data)\n",
    "pd.Categorical(encoded_data)\n",
    "\n",
    "# mã hóa cột ProductName với Label encoder sử dụng pandas\n",
    "#df2['ProductName'].astype('category').cat.codes\n",
    "\n",
    "\n",
    "#====== RỜI RẠC HÓA DỮ LIỆU ========\n",
    "\n",
    "# chia thành 5 khoảng giá trị có độ dài bằng nhau\n",
    "cats = pd.cut(df2['Price'], 5)\n",
    "# số lượng phần từ ở mỗi phần\n",
    "pd.value_counts(cats)\n",
    "\n",
    "# chia thành 5 phần có số lượng phần tử tương đương nhau\n",
    "cats = pd.qcut(df2['Price'], 5)\n",
    "# số lượng phần từ ở mỗi phần\n",
    "pd.value_counts(cats)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "# đọc dữ liệu\n",
    "df = pd.read_csv(\"OnlineRetail.csv\", encoding = \"ISO-8859-1\")\n",
    "\n",
    "# in ra kich thuoc du lieu\n",
    "df.shape\n",
    "\n",
    "\n",
    "#kiểm tra dữ liệu khuyết thiếu\n",
    "df9 = df.query('Quantity <0 and UnitPrice <=0')\n",
    "\n",
    "#Xóa bỏ dòng ngoại lai của Quantity\n",
    "df = df[df['Quantity'] >= 0]\n",
    "\n",
    "# xóa những dòng chứa giá trị bị khuyết\n",
    "df1 = df.dropna()\n",
    "# xóa những dòng chứa toàn giá trị khuyết\n",
    "df2 = df.dropna(how='all')\n",
    "\n",
    "# giữ những dòng có ít nhất 7 giá trị không bị khuyết\n",
    "df3 = df.dropna(thresh=7)\n",
    "# xóa những hàng mà có giá trị bị khuyết trên cột CustomerID\n",
    "df4 = df.dropna(subset=[\"CustomerID\"])\n",
    "# thay thế những giá trị bị khuyết trên cột CustomerID bằng giá trị -1\n",
    "df5 = df\n",
    "df5['CustomerID'] = df['CustomerID'].fillna(-1)\n",
    "# thay thế các giá trị bị khuyết ở cột Country bằng giá trị trước nó\n",
    "df5['Country'] = df['Country'].fillna(method='ffill')\n",
    "\n",
    "\n",
    "#========== XỬ LÍ DỮ LIỆU NGOẠI LAI================\n",
    " # vẽ box plot cho dữ liệu ở cột Quantity\n",
    "#sns.boxplot(x=df1['Quantity'])\n",
    "\n",
    "#IQR\n",
    "Q1 = df1['Quantity'].quantile(0.25)\n",
    "Q3 = df1['Quantity'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# xác định phần tử không phải ngoại lai\n",
    "df6 = df1\n",
    "df6['outlier'] = ~((df1['Quantity'] < (Q1 - 1.5*IQR)) | (df1['Quantity'] > (Q3 + 1.5*IQR)))\n",
    "# xóa phẩn từ ngoại lai \n",
    "df6 = df6[df6['outlier'] == True]\n",
    "\n",
    "# vẽ box plot cho dữ liệu ở cột Quantity\n",
    "\n",
    "sns.boxplot(x=df6['Quantity'])\n",
    "\n",
    "# chuẩn hóa dữ liệu với minmax scaling\n",
    "scaler = MinMaxScaler()\n",
    "# Chuẩn hóa dữ liệu trong df với MinMaxScaler ở 2 cột Quantity và UnitPrice\n",
    "df_s = scaler.fit_transform(df1[['Quantity']])\n",
    "# mô tả dữ liệu sau chuẩn hóa\n",
    "pd.DataFrame(df_s).describe()\n",
    "# vẽ lại biểu đồ hộp\n",
    "sns.boxplot(x=df_s)\n",
    "\n",
    "# chuẩn hóa dữ liệu với robust scaling\n",
    "scaler = RobustScaler()\n",
    "# Chuẩn hóa dữ liệu trong df với RobustScaler ở 2 cột Quantity và UnitPrice\n",
    "df_s = scaler.fit_transform(df1[['Quantity','UnitPrice']])\n",
    "# mô tả dữ liệu sau chuẩn hóa\n",
    "pd.DataFrame(df_s).describe()\n",
    "# vẽ lại biểu đồ hộp\n",
    "sns.boxplot(x=df_s)\n",
    "\n",
    "\n",
    "# chuẩn hóa dữ liệu với z-score scaling\n",
    "scaler = StandardScaler()\n",
    "# Chuẩn hóa dữ liệu trong df với StandardScaler ở 2 cột Quantity và UnitPrice\n",
    "df_s = scaler.fit_transform(df1[['Quantity']])\n",
    "sns.boxplot(x=df_s)\n",
    "sns.kdeplot(data=df_s)\n",
    "\n",
    "#============MÃ HÓA DỮ LIỆU==============\n",
    "# các giá trị ở cột Country\n",
    "df1['Country'].unique()\n",
    "\n",
    "\n",
    "# mã hóa cột Country với One-hot encoder sử dụng scikit learn\n",
    "encoder = OneHotEncoder()\n",
    "encoded_data = encoder.fit_transform(np.asarray(df1['Country']).reshape(-1,1))\n",
    "encoded_data.todense()\n",
    "# mã hóa cột Country với One-hot encoder sử dụng pandas\n",
    "pd.get_dummies(df1['Country'])\n",
    "\n",
    "# mã hóa cột Country với Label encoder sử dụng scikit learn\n",
    "encoder = LabelEncoder()\n",
    "encoded_data = encoder.fit_transform(np.asarray(df1['Country']))\n",
    "encoded_data\n",
    "# mã hóa cột Country với Label encoder sử dụng pandas\n",
    "df1['Country'].astype('category').cat.codes\n",
    "\n",
    "\n",
    "#===========RỜI RẠC HÓA DỮ LIỆU================\n",
    "\n",
    "\n",
    "#Rời rạc hóa dữ liệu ở cột UnitPrice\n",
    "# chia thành 4 khoảng giá trị có độ dài bằng nhau\n",
    "cats = pd.cut(df1['UnitPrice'], 4)\n",
    "# số lượng phần từ ở mỗi phần\n",
    "pd.value_counts(cats)\n",
    "\n",
    "\n",
    "# chia thành 4 phần có số lượng phần tử tương đương nhau\n",
    "cats = pd.qcut(df1['UnitPrice'], 4)\n",
    "# số lượng phần từ ở mỗi phần\n",
    "pd.value_counts(cats)\n",
    "df6.shape[0]*100/df.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "df= pd.read_csv('Credit_Scoring.csv')\n",
    "\n",
    "\n",
    "#Nêu thông tin về kiểu dữ liệu và khoảng dữ liệu ở các cột\n",
    "#df.shape\n",
    "#df.info()\n",
    "#Kiểm tra dữ liệu khuyết thiếu\n",
    "df1 = df.isna().values.any() # có tồn tại giá trị khuyết thiếu hay ko\n",
    "a = df.isna() # kiểm tra bằng true false\n",
    "\n",
    "#Thực hiện xử lý giá trị khuyết thiếu: Thay thế giá trị khuyết thiếu bằng giá trị nội suy theo các cột\n",
    "df2 = df.interpolate(axis=1)\n",
    "\n",
    "\n",
    "#Thực hiện xử lý giá trị khuyết thiếu: Thay thế giá trị khuyết thiếu bằng giá trị 0\n",
    "df3 = df.fillna(0)\n",
    "\n",
    "#Vẽ biểu đồ boxplot, biểu đồ phân bố dữ liệu cho các cột\n",
    "#sns.boxplot(df)\n",
    "#Loại bỏ giá trị ngoại lai\n",
    "Q1 = df2.quantile(0.25)\n",
    "Q3 = df2.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df5 = df2\n",
    "df5 = ~((df2 < (Q1 - 1.5 * IQR))|(df2 > (Q3 + 1.5 * IQR)))\n",
    "df5 = df5[df5 == True]\n",
    "\n",
    "#Chia dữ liệu ở các cột thành 4,5,6 nhóm có số lượng phần tử bằng nhau và đếm số lượng phần tử ở mỗi nhóm, lấy ra khoảng giữ liệu của mỗi nhóm.\n",
    "#===========RỜI RẠC HÓA DỮ LIỆU================\n",
    "# chia thành 4 khoảng giá trị có độ dài bằng nhau\n",
    "\n",
    "cats = pd.cut(df5['MonthlyIncome'], 5)\n",
    "cats\n",
    "# số lượng phần từ ở mỗi phần\n",
    "pd.value_counts(cats)\n",
    "\n",
    "#qcut\n",
    "bins = [0, 30, 40, 50, 80, 150]\n",
    "cats = pd.qcut(df5['MonthlyIncome'], bins)\n",
    "cats\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Chia dữ liệu ở các cột age và MonthlyIncome thành 5 nhóm theo các khoảng: 0, 30, 40, 50, 80, 150 và đếm số lượng phần tử ở mỗi nhóm.\n",
    "#Đặt tên bất kỳ cho các nhóm ở 2 ý trên."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import  cac model hoi quy\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd \n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "#preprocessing\n",
    "# tên xe(str), số cửa, chiều dài, mã lực, nguyên lieu(str), độ an toàn\n",
    "def branch_name_process(df, column):\n",
    "    unique_branch = list(pd.unique(df[column]))\n",
    "    for idx, branch_name in enumerate(unique_branch):\n",
    "        # get index\n",
    "        index = df.index[df[column] == branch_name].tolist()\n",
    "        df.loc[index,column] = int(idx)\n",
    "    return df\n",
    "\n",
    "def convert_street_to_id(value):\n",
    "    if value==None:\n",
    "        return 0\n",
    "    if value =='Ngõ 4 ô tô trở lên':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "# Quy trinh xay dung mo hinh  hoi quy tuyen tinh\n",
    "# b1: chon feature dac trung nao de dua mo hinh du doan\n",
    "df = pd.read_csv(\"data\\Case_study_CarPrice_Assignment.csv\")\n",
    "df['BranchName'] = df.apply(lambda x:str(x['CarName']).split(\" \")[0],axis=1).reset_index(drop=True)\n",
    "\n",
    "# su dung cong cu cua pandas(requirments: du  lieu cot nay phai co dinh, ko thay doi)\n",
    "df['BranchName'] = df['BranchName'].astype('category').cat.codes\n",
    "# tmp = df.corr()\n",
    "\n",
    "# print(tmp.head(1))\n",
    "\n",
    "# b2: loc nhieu(cuc ky quan trong)\n",
    "target = df[['carwidth','curbweight','enginesize','citympg','highwaympg','BranchName', 'price']]\n",
    "# print(target.head(5))\n",
    "# carwidth,curbweight,enginesize,citympg,highwaympg,BranchName, price\n",
    "# boxplot , 6-7 sort theo values\n",
    "\n",
    "\n",
    "# b3: normalizer data \n",
    "\n",
    "# b4: chon mo hinh (overview, compare cac mo hinh lai vs nhau: metrics)\n",
    "\n",
    "# linear, randomforest, bootrap\n",
    "# poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "\n",
    "# split du lieu\n",
    "X, y = target[['carwidth','curbweight','enginesize','citympg','highwaympg','BranchName']], df['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "regressor = DecisionTreeRegressor(random_state=0)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "pred = regressor.predict(X_test)\n",
    "print(\"MAPE: \",mean_absolute_percentage_error(y_test, pred))\n",
    "# metrics\n",
    "\n",
    "# b5: finuntune hyperparameter?? girdsearch, fintune cac thong so mo hinh \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': [3, 10], 'max_features': [2, 4, 6]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "]\n",
    "grid_search = GridSearchCV(regressor, param_grid, cv=2,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           refit=True)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "grid_search.best_params_.predict(X_test)\n",
    "print(\"MAPE: \",mean_absolute_percentage_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\Case_study_CarPrice_Assignment.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18492\\2703785639.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m# Quy trinh xay dung mo hinh  hoi quy tuyen tinh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m# b1: chon feature dac trung nao de dua mo hinh du doan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data\\Case_study_CarPrice_Assignment.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'BranchName'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CarName'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"encoding_errors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data\\\\Case_study_CarPrice_Assignment.csv'"
     ]
    }
   ],
   "source": [
    "# import  cac model hoi quy\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd \n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "#preprocessing\n",
    "# tên xe(str), số cửa, chiều dài, mã lực, nguyên lieu(str), độ an toàn\n",
    "def branch_name_process(df, column):\n",
    "    unique_branch = list(pd.unique(df[column]))\n",
    "    for idx, branch_name in enumerate(unique_branch):\n",
    "        # get index\n",
    "        index = df.index[df[column] == branch_name].tolist()\n",
    "        df.loc[index,column] = int(idx)\n",
    "    return df\n",
    "\n",
    "def convert_street_to_id(value):\n",
    "    if value==None:\n",
    "        return 0\n",
    "    if value =='Ngõ 4 ô tô trở lên':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "# Quy trinh xay dung mo hinh  hoi quy tuyen tinh\n",
    "# b1: chon feature dac trung nao de dua mo hinh du doan\n",
    "df = pd.read_csv(\"\")\n",
    "df['BranchName'] = df.apply(lambda x:str(x['CarName']).split(\" \")[0],axis=1).reset_index(drop=True)\n",
    "\n",
    "# su dung cong cu cua pandas(requirments: du  lieu cot nay phai co dinh, ko thay doi)\n",
    "df['BranchName'] = df['BranchName'].astype('category').cat.codes\n",
    "# tmp = df.corr()\n",
    "\n",
    "# print(tmp.head(1))\n",
    "\n",
    "# b2: loc nhieu(cuc ky quan trong)\n",
    "target = df[['carwidth','curbweight','enginesize','citympg','highwaympg','BranchName', 'price']]\n",
    "# print(target.head(5))\n",
    "# carwidth,curbweight,enginesize,citympg,highwaympg,BranchName, price\n",
    "# boxplot , 6-7 sort theo values\n",
    "\n",
    "\n",
    "# b3: normalizer data \n",
    "\n",
    "# b4: chon mo hinh (overview, compare cac mo hinh lai vs nhau: metrics)\n",
    "\n",
    "# linear, randomforest, bootrap\n",
    "# poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "\n",
    "# split du lieu\n",
    "X, y = target[['carwidth','curbweight','enginesize','citympg','highwaympg','BranchName']], df['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "regressor = DecisionTreeRegressor(random_state=0)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "pred = regressor.predict(X_test)\n",
    "print(\"MAPE: \",mean_absolute_percentage_error(y_test, pred))\n",
    "# metrics\n",
    "\n",
    "# b5: finuntune hyperparameter?? girdsearch, fintune cac thong so mo hinh \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': [3, 10], 'max_features': [2, 4, 6]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "]\n",
    "grid_search = GridSearchCV(regressor, param_grid, cv=2,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           refit=True)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "grid_search.best_params_.predict(X_test)\n",
    "print(\"MAPE: \",mean_absolute_percentage_error(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e830c59da599f1996693fd066ec76c44ca94e938461f68cfd4485db148307566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
